{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-173-90f346d895d7>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-173-90f346d895d7>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    garbage_columns = [np.unique(X[Y==0,attr]).size == 1 || attr >= 68 for attr in range(75)]\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = \"cleveland.data\"\n",
    "\n",
    "with open(filename, 'r', encoding='ascii') as f:\n",
    "    values = [word for line in f for word in line.split()]\n",
    "    data_processed = np.reshape(np.array(values), (-1, 76))\n",
    "\n",
    "flatten = np.vectorize(lambda x: 1 if x != 0 else 0)\n",
    "Y = flatten(to_int(data_processed[:, 58 - 1]))\n",
    "\n",
    "to_int = np.vectorize(float)\n",
    "X = to_int(data_processed[:, :-1:]) \n",
    "\n",
    "# exclude columns for which all non-diseased people have the same value\n",
    "garbage_columns = [np.unique(X[Y==0,attr]).size == 1 || attr >= 68 for attr in range(75)]\n",
    "columns_to_exclude = np.where(np.array(garbage_columns))[0]\n",
    "\n",
    "# diabetic?\n",
    "d = data_processed[:, 17 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1.,    0.,   63., ...,    1.,   -9.,   -9.],\n",
       "       [   2.,    0.,   67., ...,    1.,   -9.,   -9.],\n",
       "       [   3.,    0.,   67., ...,    3.,   -9.,   -9.],\n",
       "       ..., \n",
       "       [ 296.,    0.,   58., ...,    1.,   -9.,   -9.],\n",
       "       [ 297.,    0.,   57., ...,    1.,   -9.,   -9.],\n",
       "       [ 298.,    0.,   47., ...,    1.,   -9.,   -9.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X[Y==0,60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis using ANOVA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=2.7849569187612762, pvalue=0.096270975783822321)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "diabetic = X[:, 17 - 1] == 1\n",
    "stats.f_oneway(Y[diabetic], Y[np.logical_not(diabetic)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA indicates a p-value of 0.09, a little promising. Now let's try basic logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=4, random_state=None, shuffle=False)\n",
      "[57] 1.0\n",
      "[57, 0] 1.0\n",
      "[57, 0, 1] 1.0\n",
      "[57, 0, 1, 2] 1.0\n",
      "[57, 0, 1, 2, 3] 1.0\n",
      "[57, 0, 1, 2, 3, 4] 1.0\n",
      "[57, 0, 1, 2, 3, 4, 5] 1.0\n",
      "[57, 0, 1, 2, 3, 4, 5, 6] 1.0\n",
      "[57, 0, 1, 2, 3, 4, 5, 6, 7] 1.0\n",
      "[57, 0, 1, 2, 3, 4, 5, 6, 7, 8] 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[57, 0, 1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf.get_n_splits(X)\n",
    "print(kf)\n",
    "\n",
    "def kfold_validate (X_sub, k):\n",
    "    kf = KFold(n_splits = k)\n",
    "    sum = 0\n",
    "    for train, test in kf.split(X_sub):\n",
    "        reg = linear_model.LogisticRegression()\n",
    "        reg.fit(X_sub[train], Y[train])\n",
    "        sum += (reg.score(X_sub[test], Y[test]))\n",
    "    return sum / k\n",
    "        \n",
    "def filter_select(X, Y, num_features):\n",
    "    # ignore the bad columns\n",
    "    avail_features = list(range(0, 74))\n",
    "    for garbage_col in columns_to_exclude:\n",
    "        avail_features.remove(garbage_col)\n",
    "        \n",
    "    included_features = [] #[17 - 1] # diabetes    \n",
    "    for i in range(num_features):\n",
    "        best_feature = -1\n",
    "        best_score = -1\n",
    "        for feature in avail_features:\n",
    "            score = kfold_validate(X[:,included_features + [feature]], 4)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_feature = feature\n",
    "        included_features += [best_feature]\n",
    "        avail_features.remove(best_feature)\n",
    "        print(included_features, best_score)\n",
    "    return included_features\n",
    "            \n",
    "filter_select(X, Y, 10)\n",
    "#for i in range(76):\n",
    "#    reg = linear_model.LogisticRegression()\n",
    "#    reg.fit(X, Y)\n",
    "#    reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.6879999999999997, 3.7006369426751591)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X[Y==1, 50]),np.mean(X[Y==0, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
